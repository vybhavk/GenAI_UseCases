{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPo2xqwDVQmhCqpgG3g3KP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vybhavk/GenAI_UseCases/blob/main/GenAI_Coder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z76TFiIRW4pU",
        "outputId": "04356442-849e-4c46-b0bd-50e84e51c314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Its running on Colab\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.27 (from langchain)\n",
            "  Downloading langchain_core-0.2.29-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.98-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting openai<2.0.0,>=1.40.0 (from langchain_openai)\n",
            "  Downloading openai-1.40.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain_openai) (1.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading langchain-0.2.12-py3-none-any.whl (990 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.29-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.98-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.40.3-py3-none-any.whl (360 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.7/360.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, jiter, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain-text-splitters, langchain_openai, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.12 langchain-core-0.2.29 langchain-text-splitters-0.2.2 langchain_openai-0.1.21 langsmith-0.1.98 openai-1.40.3 orjson-3.10.7 tenacity-8.5.0 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "  from google.colab import drive, userdata\n",
        "  COLAB = True\n",
        "  print(\"Its running on Colab\")\n",
        "except:\n",
        "  COLAB = False\n",
        "  print(\"Its not running on Colab\")\n",
        "\n",
        "if COLAB:\n",
        "  os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "  !pip install langchain langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts.chat import PromptTemplate\n",
        "from IPython.display import display_markdown\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "TEMPLATE = \"\"\"The following is a friendly conversation between a human and an\n",
        "AI to generate Python code. If you have notes about the code, place them before\n",
        "the code. Any nots about execution should follow the code. If you do mix any\n",
        "notes with the code, make them comments. Add proper comments to the code.\n",
        "Sort imports and follow PEP-8 formatting.\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Human: {input}\n",
        "Code Assistant:\"\"\"\n",
        "PROMPT_TEMPLATE = PromptTemplate(input_variables=[\"history\", \"input\"], template=TEMPLATE)\n",
        "\n",
        "def start_conversation():\n",
        "    # Initialize the OpenAI LLM with your API key\n",
        "    llm = ChatOpenAI(\n",
        "        model=MODEL,\n",
        "        temperature=0.0,\n",
        "        n=1\n",
        "    )\n",
        "\n",
        "    # Initialize memory and conversation\n",
        "    memory = ConversationBufferWindowMemory()\n",
        "    conversation = ConversationChain(\n",
        "        prompt=PROMPT_TEMPLATE,\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return conversation\n",
        "\n",
        "def generate_code(conversation, prompt):\n",
        "    print(\"Model response:\")\n",
        "    output = conversation.invoke(prompt)\n",
        "    display_markdown(output['response'], raw=True)"
      ],
      "metadata": {
        "id": "v2zrz2pfYPYP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = start_conversation()\n",
        "generate_code(conversation, \"\"\"Write Python code to learn the XOR function with PyTorch.\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yZjeJSJFgxSL",
        "outputId": "8201248b-87b4-4ad9-9bf1-f5aaac6d50b0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use RunnableWithMessageHistory: https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Sure! Below is a Python code snippet that demonstrates how to learn the XOR function using PyTorch. The code includes comments to explain each part of the process.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the XOR dataset\n# Input: 2 features (x1, x2), Output: 1 target (y)\ndata = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\nlabels = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Define a simple neural network model\nclass XORModel(nn.Module):\n    def __init__(self):\n        super(XORModel, self).__init__()\n        # Input layer to hidden layer\n        self.hidden = nn.Linear(2, 2)\n        # Hidden layer to output layer\n        self.output = nn.Linear(2, 1)\n        # Activation function\n        self.activation = nn.Sigmoid()\n\n    def forward(self, x):\n        # Forward pass through the network\n        hidden_output = self.activation(self.hidden(x))\n        output = self.activation(self.output(hidden_output))\n        return output\n\n# Initialize the model, loss function, and optimizer\nmodel = XORModel()\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n\n# Training the model\nnum_epochs = 10000  # Number of training epochs\nfor epoch in range(num_epochs):\n    # Zero the gradients\n    optimizer.zero_grad()\n    \n    # Forward pass\n    outputs = model(data)\n    \n    # Compute the loss\n    loss = criterion(outputs, labels)\n    \n    # Backward pass and optimization\n    loss.backward()\n    optimizer.step()\n    \n    # Print the loss every 1000 epochs\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the model\nwith torch.no_grad():\n    test_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n    predictions = model(test_data)\n    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary output\n    print(\"Predictions:\")\n    print(predicted_classes)\n```\n\n### Notes on Execution:\n- Make sure you have PyTorch installed in your Python environment. You can install it using pip:\n  ```bash\n  pip install torch\n  ```\n- The model is trained for 10,000 epochs, which should be sufficient for it to learn the XOR function. You can adjust the number of epochs or the learning rate if needed.\n- The output will show the loss during training and the final predictions for the XOR inputs after training. The expected output for the XOR function is:\n  - (0, 0) -> 0\n  - (0, 1) -> 1\n  - (1, 0) -> 1\n  - (1, 1) -> 0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_code(conversation, \"\"\"Could you make use of a PyTorch sequence rather than a nn.Module class?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jtgJvngSg0-F",
        "outputId": "0b97056c-efd3-438a-ddb2-da28585094d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Certainly! Below is the modified Python code that uses a PyTorch `nn.Sequential` instead of defining a custom `nn.Module` class. This approach simplifies the model definition by stacking layers in a sequential manner.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the XOR dataset\n# Input: 2 features (x1, x2), Output: 1 target (y)\ndata = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\nlabels = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Define a simple neural network model using nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(2, 2),  # Input layer to hidden layer\n    nn.Sigmoid(),     # Activation function for hidden layer\n    nn.Linear(2, 1),  # Hidden layer to output layer\n    nn.Sigmoid()      # Activation function for output layer\n)\n\n# Initialize the loss function and optimizer\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n\n# Training the model\nnum_epochs = 10000  # Number of training epochs\nfor epoch in range(num_epochs):\n    # Zero the gradients\n    optimizer.zero_grad()\n    \n    # Forward pass\n    outputs = model(data)\n    \n    # Compute the loss\n    loss = criterion(outputs, labels)\n    \n    # Backward pass and optimization\n    loss.backward()\n    optimizer.step()\n    \n    # Print the loss every 1000 epochs\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the model\nwith torch.no_grad():\n    test_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n    predictions = model(test_data)\n    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary output\n    print(\"Predictions:\")\n    print(predicted_classes)\n```\n\n### Notes on Execution:\n- Ensure you have PyTorch installed in your Python environment. You can install it using pip:\n  ```bash\n  pip install torch\n  ```\n- The model is trained for 10,000 epochs, which should be sufficient for it to learn the XOR function. You can adjust the number of epochs or the learning rate if needed.\n- The output will show the loss during training and the final predictions for the XOR inputs after training. The expected output for the XOR function is:\n  - (0, 0) -> 0\n  - (0, 1) -> 1\n  - (1, 0) -> 1\n  - (1, 1) -> 0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_code(conversation, \"\"\"Could you make use of a PyTorch sequence rather than a nn.Module class?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZeJkdtYag8nS",
        "outputId": "f8c7a354-4924-43fe-d945-c867535a907f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Certainly! Below is the modified Python code that uses a PyTorch `nn.Sequential` instead of defining a custom `nn.Module` class. This approach simplifies the model definition by stacking layers in a sequential manner.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Define the XOR dataset\n# Input: 2 features (x1, x2), Output: 1 target (y)\ndata = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\nlabels = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Define a simple neural network model using nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(2, 2),  # Input layer to hidden layer\n    nn.Sigmoid(),     # Activation function for hidden layer\n    nn.Linear(2, 1),  # Hidden layer to output layer\n    nn.Sigmoid()      # Activation function for output layer\n)\n\n# Initialize the loss function and optimizer\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.SGD(model.parameters(), lr=0.1)  # Stochastic Gradient Descent\n\n# Training the model\nnum_epochs = 10000  # Number of training epochs\nfor epoch in range(num_epochs):\n    # Zero the gradients\n    optimizer.zero_grad()\n    \n    # Forward pass\n    outputs = model(data)\n    \n    # Compute the loss\n    loss = criterion(outputs, labels)\n    \n    # Backward pass and optimization\n    loss.backward()\n    optimizer.step()\n    \n    # Print the loss every 1000 epochs\n    if (epoch + 1) % 1000 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the model\nwith torch.no_grad():\n    test_data = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n    predictions = model(test_data)\n    predicted_classes = (predictions > 0.5).float()  # Convert probabilities to binary output\n    print(\"Predictions:\")\n    print(predicted_classes)\n```\n\n### Notes on Execution:\n- Ensure you have PyTorch installed in your Python environment. You can install it using pip:\n  ```bash\n  pip install torch\n  ```\n- The model is trained for 10,000 epochs, which should be sufficient for it to learn the XOR function. You can adjust the number of epochs or the learning rate if needed.\n- The output will show the loss during training and the final predictions for the XOR inputs after training. The expected output for the XOR function is:\n  - (0, 0) -> 0\n  - (0, 1) -> 1\n  - (1, 0) -> 1\n  - (1, 1) -> 0"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Start a new conversation\n",
        "conversation = start_conversation()\n",
        "generate_code(conversation, \"\"\"\n",
        "Can you provide Python code using PyTorch to effectively learn the XOR function\n",
        "with 4 hidden neurons, using the Adam optimizer, and 20K training epochs?\n",
        "Use a sequence not a nn.Module class.\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "xweMKtdwhS-0",
        "outputId": "7ee186d0-5b68-4b1e-952c-6cf90c719691"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Sure! Below is the Python code that uses PyTorch to learn the XOR function with 4 hidden neurons, utilizing the Adam optimizer and training for 20,000 epochs. The code is structured in a sequential manner rather than using a `nn.Module` class.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Set the random seed for reproducibility\ntorch.manual_seed(0)\n\n# Define the XOR input and output\nX = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\ny = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Create a sequential model\nmodel = nn.Sequential(\n    nn.Linear(2, 4),  # Input layer to hidden layer with 4 neurons\n    nn.ReLU(),        # Activation function\n    nn.Linear(4, 1),  # Hidden layer to output layer\n    nn.Sigmoid()      # Sigmoid activation for binary output\n)\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer\n\n# Training loop\nnum_epochs = 20000\nfor epoch in range(num_epochs):\n    # Forward pass: compute predicted y by passing x to the model\n    y_pred = model(X)\n\n    # Compute and print loss\n    loss = criterion(y_pred, y)\n    \n    # Zero gradients, backward pass, and optimize\n    optimizer.zero_grad()  # Clear previous gradients\n    loss.backward()        # Backpropagation\n    optimizer.step()       # Update weights\n\n    # Print loss every 2000 epochs\n    if (epoch + 1) % 2000 == 0:\n        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n\n# Test the model\nwith torch.no_grad():\n    test_output = model(X)\n    predicted = (test_output > 0.5).float()  # Convert probabilities to binary output\n    print(\"Predicted outputs:\\n\", predicted)\n```\n\n### Notes on Execution:\n- Ensure you have PyTorch installed in your Python environment. You can install it using pip if you haven't done so already: `pip install torch`.\n- The model is trained for 20,000 epochs, which may take some time depending on your hardware.\n- The output will show the loss at every 2000 epochs, and finally, it will print the predicted outputs for the XOR function.\n- The predicted outputs will be in binary format (0 or 1) based on the learned model."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Set the random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Define the XOR input and output\n",
        "X = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
        "y = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n",
        "\n",
        "# Create a sequential model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(2, 4),  # Input layer to hidden layer with 4 neurons\n",
        "    nn.ReLU(),        # Activation function\n",
        "    nn.Linear(4, 1),  # Hidden layer to output layer\n",
        "    nn.Sigmoid()      # Sigmoid activation for binary output\n",
        ")\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 20000\n",
        "for epoch in range(num_epochs):\n",
        "    # Forward pass: compute predicted y by passing x to the model\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "\n",
        "    # Zero gradients, backward pass, and optimize\n",
        "    optimizer.zero_grad()  # Clear previous gradients\n",
        "    loss.backward()        # Backpropagation\n",
        "    optimizer.step()       # Update weights\n",
        "\n",
        "    # Print loss every 2000 epochs\n",
        "    if (epoch + 1) % 2000 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Test the model\n",
        "with torch.no_grad():\n",
        "    test_output = model(X)\n",
        "    predicted = (test_output > 0.5).float()  # Convert probabilities to binary output\n",
        "    print(\"Predicted outputs:\\n\", predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6vl704KhX6v",
        "outputId": "2cb05d45-83b5-49ac-c935-75ab049fc26e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2000/20000], Loss: 0.0007\n",
            "Epoch [4000/20000], Loss: 0.0001\n",
            "Epoch [6000/20000], Loss: 0.0000\n",
            "Epoch [8000/20000], Loss: 0.0000\n",
            "Epoch [10000/20000], Loss: 0.0000\n",
            "Epoch [12000/20000], Loss: 0.0000\n",
            "Epoch [14000/20000], Loss: 0.0000\n",
            "Epoch [16000/20000], Loss: 0.0000\n",
            "Epoch [18000/20000], Loss: 0.0000\n",
            "Epoch [20000/20000], Loss: 0.0000\n",
            "Predicted outputs:\n",
            " tensor([[0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_code(conversation, \"\"\"Can you write unit tests for the same\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cRTHEfWoi31O",
        "outputId": "0c6c0b50-5c8c-4e55-eb19-7c0b5b7d32fd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Certainly! Below is a set of unit tests for the XOR function model implemented in PyTorch. These tests will check if the model can correctly predict the XOR outputs after training. The tests will use the `unittest` framework.\n\n```python\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport unittest\n\n# Set the random seed for reproducibility\ntorch.manual_seed(0)\n\n# Define the XOR input and output\nX = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\ny = torch.tensor([[0], [1], [1], [0]], dtype=torch.float32)\n\n# Create a sequential model\nmodel = nn.Sequential(\n    nn.Linear(2, 4),  # Input layer to hidden layer with 4 neurons\n    nn.ReLU(),        # Activation function\n    nn.Linear(4, 1),  # Hidden layer to output layer\n    nn.Sigmoid()      # Sigmoid activation for binary output\n)\n\n# Define the loss function and optimizer\ncriterion = nn.BCELoss()  # Binary Cross Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=0.01)  # Adam optimizer\n\n# Training loop\nnum_epochs = 20000\nfor epoch in range(num_epochs):\n    # Forward pass: compute predicted y by passing x to the model\n    y_pred = model(X)\n\n    # Compute and print loss\n    loss = criterion(y_pred, y)\n    \n    # Zero gradients, backward pass, and optimize\n    optimizer.zero_grad()  # Clear previous gradients\n    loss.backward()        # Backpropagation\n    optimizer.step()       # Update weights\n\n# Unit tests for the XOR model\nclass TestXORModel(unittest.TestCase):\n    def test_model_output(self):\n        \"\"\"Test if the model outputs are close to expected XOR results.\"\"\"\n        with torch.no_grad():\n            test_output = model(X)\n            predicted = (test_output > 0.5).float()  # Convert probabilities to binary output\n            expected = y  # Expected output for XOR\n            self.assertTrue(torch.all(predicted.eq(expected)), \"Model did not predict XOR correctly.\")\n\n    def test_loss_decreases(self):\n        \"\"\"Test if the loss decreases over epochs.\"\"\"\n        initial_loss = criterion(model(X), y).item()\n        for epoch in range(1000):  # Check loss over a smaller number of epochs\n            y_pred = model(X)\n            loss = criterion(y_pred, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n        final_loss = criterion(model(X), y).item()\n        self.assertLess(final_loss, initial_loss, \"Loss did not decrease after training.\")\n\nif __name__ == '__main__':\n    unittest.main()\n```\n\n### Notes on Execution:\n- Ensure you have the `unittest` framework available in your Python environment (it is included in the standard library).\n- You can run the tests by executing the script. If the tests pass, it indicates that the model is functioning correctly for the XOR problem.\n- The first test checks if the model's predictions match the expected XOR outputs, while the second test verifies that the loss decreases during training.\n- You may want to adjust the number of epochs in the `test_loss_decreases` method to suit your testing needs."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "# Unit tests for the XOR model\n",
        "class TestXORModel(unittest.TestCase):\n",
        "    def test_model_output(self):\n",
        "        \"\"\"Test if the model outputs are close to expected XOR results.\"\"\"\n",
        "        with torch.no_grad():\n",
        "            test_output = model(X)\n",
        "            predicted = (test_output > 0.5).float()  # Convert probabilities to binary output\n",
        "            expected = y  # Expected output for XOR\n",
        "            self.assertTrue(torch.all(predicted.eq(expected)), \"Model did not predict XOR correctly.\")\n",
        "\n",
        "    def test_loss_decreases(self):\n",
        "        \"\"\"Test if the loss decreases over epochs.\"\"\"\n",
        "        initial_loss = criterion(model(X), y).item()\n",
        "        for epoch in range(1000):  # Check loss over a smaller number of epochs\n",
        "            y_pred = model(X)\n",
        "            loss = criterion(y_pred, y)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        final_loss = criterion(model(X), y).item()\n",
        "        self.assertLess(final_loss, initial_loss, \"Loss did not decrease after training.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main()"
      ],
      "metadata": {
        "id": "Bjq6WItbjJxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YZOq6QSUjQbY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}